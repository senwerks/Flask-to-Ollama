# Flask-to-Ollama

A flask-based web-app for talking to local LLMs via Ollama.

Automatically gets the list of models installed in Ollama and lets you send prompts to them.

Project dependencies setup for `uv`, so run with `uv run app.py`, or if you prefer `pip` then do `pip install flask requests` then `flask run`

![Screenshot of Flask-to-Ollama](https://raw.githubusercontent.com/senwerks/Flask-to-Ollama/refs/heads/main/flask-to-ollama.png)
